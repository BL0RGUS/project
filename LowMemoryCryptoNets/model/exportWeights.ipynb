{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_masks(img_width, kernel_size, out_channels=16):\n",
    "    masks = []\n",
    "    for k in range(kernel_size**2):\n",
    "        mask = []\n",
    "        rows = 0   \n",
    "        ## first row of mask, ll 0s if in first 3 kernels\n",
    "        if k < kernel_size:\n",
    "            for i in range(img_width):\n",
    "                mask.append(0)\n",
    "            rows += 1\n",
    "        \n",
    "        # middle rows, a and b are values of the left and rightmost columns\n",
    "        a = int(k % kernel_size != 0)\n",
    "        b = int((k+1) % kernel_size != 0)\n",
    "        for j in range(img_width-rows):\n",
    "            mask.append(a)\n",
    "            for i in range(img_width-2):\n",
    "                mask.append(1)\n",
    "            mask.append(b)\n",
    "            rows += 1\n",
    "        \n",
    "        # last row\n",
    "        if k >= kernel_size*(kernel_size-1):\n",
    "            for j in range(img_width):\n",
    "                mask[(img_width**2)-1-j] = 0\n",
    "                \n",
    "        masks.append(np.tile(np.array(mask), out_channels))\n",
    "    return masks\n",
    "'''\n",
    "def build_mask(starting_padding, ending_padding, window_length, max_length):\n",
    "    mask = []\n",
    "    for i in range(starting_padding):\n",
    "        mask.append(0)\n",
    "    while len(mask) < (max_length - ending_padding):\n",
    "        for j in range(window_length):\n",
    "            mask.append(1)\n",
    "        mask.append(0)\n",
    "        \n",
    "    while len(mask) > max_length:\n",
    "        mask.pop()\n",
    "    while len(mask) < max_length:\n",
    "        mask.append(0)\n",
    "        \n",
    "    for i in range(ending_padding):\n",
    "        mask[max_length - i - 1] = 0\n",
    "        \n",
    "    return mask\n",
    "\n",
    "\n",
    "def build_masks(img_width, kernel_size, channels_in):\n",
    "    masks = []\n",
    "    masks.append(np.tile(np.array(build_mask(img_width + 1, 0, img_width -1, img_width ** 2)), channels_in))\n",
    "    masks.append(np.tile(np.array(build_mask(img_width, 0, img_width ** 2, img_width ** 2)), channels_in))\n",
    "    masks.append(np.tile(np.array(build_mask(img_width, 0, img_width - 1, img_width ** 2)), channels_in))\n",
    "    masks.append(np.tile(np.array(build_mask(1, 0, img_width - 1, img_width ** 2)), channels_in))\n",
    "    masks.append(np.tile(np.array(build_mask(0, 0, img_width ** 2, img_width ** 2)), channels_in))\n",
    "    masks.append(np.tile(np.array(build_mask(0, 1, img_width - 1, img_width ** 2)), channels_in))\n",
    "    masks.append(np.tile(np.array(build_mask(1, img_width - 1, img_width - 1, img_width ** 2)), channels_in))\n",
    "    masks.append(np.tile(np.array(build_mask(0, img_width, img_width ** 2, img_width ** 2)), channels_in))\n",
    "    masks.append(np.tile(np.array(build_mask(0, img_width + 1, img_width - 1, img_width ** 2)), channels_in))\n",
    "    return masks\n",
    "'''    \n",
    "# converts binary mask from stride 1 to stride s\n",
    "def altalena(mask, img_width, stride=2):\n",
    "    new_v = []\n",
    "    for i in range(len(mask)):\n",
    "        if i % stride != 0:\n",
    "            new_v.append(0)\n",
    "        elif i % (img_width*stride) >= img_width:\n",
    "            new_v.append(0)\n",
    "        else:\n",
    "            new_v.append(mask[i])\n",
    "    return new_v\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this block works fine for the masks discussed in the paper, need to see under what conditions this holds generally\n",
    "# odd dimension kernel ? what size padding and stride ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initial Layer\n",
    "def initialLayer(img_width, kernel_size, channels_in, channels_out, conv_weight, bn, bin_masks):\n",
    "    #calculate weight values for affine bn\n",
    "    A = bn.weight / torch.sqrt(bn.running_var + bn.eps)\n",
    "    b = -(bn.weight * bn.running_mean / torch.sqrt(bn.running_var + bn.eps)) + bn.bias\n",
    "    print(b)\n",
    "    A = A.detach()\n",
    "    for i in range(channels_out):\n",
    "        kernels = [np.array([]) for z in range(kernel_size**2)]\n",
    "        for j in range(channels_in):\n",
    "            # specific to intial layer\n",
    "            weights = conv_weight[i][j].reshape(kernel_size**2)\n",
    "            for k in range(kernel_size**2):\n",
    "                kernels[k] = np.append(kernels[k], np.repeat(weights[k].detach(), img_width**2))\n",
    "        # fill remaining slots with 0s\n",
    "        for j in range(channels_out-channels_in):\n",
    "            for k in range(kernel_size**2):\n",
    "                kernels[k] = np.append(kernels[k], np.repeat(0, img_width**2))\n",
    "        # mask and save\n",
    "        for k in range(kernel_size**2):\n",
    "            kernels[k] = np.multiply(kernels[k], bin_masks[k])\n",
    "            kernels[k] = np.multiply(kernels[k], np.repeat(A[i], channels_out*(img_width**2)))\n",
    "            np.savetxt('../weights/conv1bn1-ch{}-k{}.bin'.format(i, k+1), kernels[k], delimiter=',')\n",
    "    np.savetxt('../weights/conv1bn1-bias.bin', np.repeat(b.detach(), img_width**2), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convbn weight encoding\n",
    "def convbn(img_width, kernel_size, channels_in, channels_out, conv_weight, bn, layerNum, convNum, bin_masks):\n",
    "    A = bn.weight / torch.sqrt(bn.running_var + bn.eps)\n",
    "    b = -(bn.weight * bn.running_mean / torch.sqrt(bn.running_var + bn.eps)) + bn.bias\n",
    "    A = A.detach()\n",
    "    for i in range(channels_in):\n",
    "        ## build repeated kernel weights\n",
    "        kernels = [np.array([]) for z in range(kernel_size**2)]\n",
    "        for j in range(channels_out):\n",
    "            weights = conv_weight[j][(j+i)%channels_in].reshape(kernel_size**2)\n",
    "            for k in range(kernel_size**2):\n",
    "                kernels[k] = np.append(kernels[k], np.repeat(weights[k].detach(), img_width**2))\n",
    "        \n",
    "        ## apply binary masks to allow for padding\n",
    "        for k in range(kernel_size**2):\n",
    "            kernels[k] = np.multiply(kernels[k], bin_masks[k])\n",
    "            kernels[k] = np.multiply(kernels[k], np.repeat(A, img_width**2))\n",
    "            kernels[k] = np.roll(kernels[k], (img_width**2)*i)\n",
    "            np.savetxt('../weights/layer{}-conv{}bn{}-ch{}-k{}.bin'.format(layerNum, convNum, convNum, i,k+1), kernels[k], delimiter=',')\n",
    "        \n",
    "    # save biases\n",
    "    np.savetxt('../weights/layer{}-conv{}bn{}-bias.bin'.format(layerNum, convNum, convNum), np.repeat(b.detach(), img_width**2), delimiter=',')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsamplingConvbn(img_width, kernel_size, channels_in, channels_out, conv_weight, bn, layerNum, convNum, bin_masks):\n",
    "    A = bn.weight / torch.sqrt(bn.running_var + bn.eps)\n",
    "    b = -(bn.weight * bn.running_mean / torch.sqrt(bn.running_var + bn.eps)) + bn.bias\n",
    "    A = A.detach()\n",
    "    for i in range(channels_in):\n",
    "        ## build repeated kernel weights\n",
    "        kernels = [np.array([]) for z in range(kernel_size**2)]\n",
    "        for j in range(channels_out):\n",
    "            weights = conv_weight[j][(j+i)%channels_in].reshape(kernel_size**2)\n",
    "            for k in range(kernel_size**2):\n",
    "                kernels[k] = np.append(kernels[k], np.repeat(weights[k].detach(), img_width**2))\n",
    "        \n",
    "        ## apply binary masks to allow for padding\n",
    "        for k in range(kernel_size**2):\n",
    "            kernels[k] = np.multiply(kernels[k], altalena(np.tile(bin_masks[k], 2), img_width))\n",
    "            kernels[k] = np.multiply(kernels[k], np.repeat(A.numpy(), img_width**2))\n",
    "            kernels[k] = np.add(kernels[k], np.roll(kernels[k], (img_width**2)*(channels_in*-1)+1))[:(img_width**2)*(channels_in)]\n",
    "            np.savetxt('../weights/layer{}-conv{}bn{}-ch{}-k{}.bin'.format(layerNum, convNum, convNum, i,k+1), altalena(np.roll(kernels[k], (img_width**2)*i), img_width), delimiter=',')\n",
    "            np.savetxt('../weights/layer{}-conv{}bn{}-ch{}-k{}.bin'.format(layerNum, convNum, convNum, i+channels_in,k+1), altalena(np.roll(kernels[k], (i*(img_width**2))-1), img_width), delimiter=',')\n",
    "    bs = b.detach().numpy()\n",
    "    bias_corrected1 = altalena(np.repeat(bs[:int(channels_out/2)], img_width**2),img_width)\n",
    "    bias_corrected2 = altalena(np.roll(np.repeat(bs[int(channels_out/2):channels_out], img_width**2), -1), img_width)\n",
    "    np.savetxt('../weights/layer{}-conv{}bn{}-bias1.bin'.format(layerNum, convNum, convNum), bias_corrected1, delimiter=',')\n",
    "    np.savetxt('../weights/layer{}-conv{}bn{}-bias2.bin'.format(layerNum, convNum, convNum), bias_corrected2, delimiter=',')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dx(img_width, channels_in, channels_out, downsample_weight, downsample_bias, layerNum, convNum, bin_masks):\n",
    "    \n",
    "    A = downsample_bias.weight / torch.sqrt(downsample_bias.running_var + downsample_bias.eps)\n",
    "    b = -(downsample_bias.weight * downsample_bias.running_mean / torch.sqrt(downsample_bias.running_var + downsample_bias.eps)) + downsample_bias.bias\n",
    "    A = A.detach()\n",
    "    for i in range(channels_in):\n",
    "        kernel = np.array([])\n",
    "        for j in range(channels_out):\n",
    "            weight = downsample_weight[j][(j+i)%channels_in].reshape(1)[0]\n",
    "            kernel = np.append(kernel, np.repeat(weight.detach(), img_width**2))\n",
    "        \n",
    "        kernel = np.multiply(kernel, altalena(np.tile(bin_masks[4],2), img_width))\n",
    "        kernel = np.multiply(kernel, np.repeat(A.numpy(), img_width**2))\n",
    "        kernel = np.add(kernel, np.roll(kernel, (img_width**2)*(channels_in*-1)+1))[:(img_width**2)*(channels_in)]\n",
    "        \n",
    "        np.savetxt('../weights/layer{}dx-conv{}bn{}-ch{}-k1.bin'.format(layerNum, convNum, convNum, i), altalena(np.roll(kernel, (img_width**2)*i), img_width), delimiter=',')\n",
    "        np.savetxt('../weights/layer{}dx-conv{}bn{}-ch{}-k1.bin'.format(layerNum, convNum, convNum, i+channels_in), altalena(np.roll(kernel, (i*(img_width**2))-1), img_width), delimiter=',')\n",
    "    bs = b.detach().numpy()\n",
    "    bias_corrected1 = altalena(np.repeat(bs[:int(channels_out/2)], img_width**2), img_width)\n",
    "    bias_corrected2 = altalena(np.repeat(bs[int(channels_out/2):channels_out], img_width**2), img_width)\n",
    "    np.savetxt('../weights/layer{}dx-conv{}bn{}-bias1.bin'.format(layerNum, convNum, convNum), bias_corrected1, delimiter=',')\n",
    "    np.savetxt('../weights/layer{}dx-conv{}bn{}-bias2.bin'.format(layerNum, convNum, convNum), bias_corrected2, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(fc_weight, i, features_out):\n",
    "    for j in range(features_out):\n",
    "        np.savetxt('../weights/fc{}-f{}.bin'.format(i, j+1), fc_weight[j].reshape(-1).detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2048, out_features=100, bias=False)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(64) \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.fc1 = nn.Linear(128*4*4,100, bias =  False)\n",
    "        self.fc2 = nn.Linear(100, 10, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu (x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = AlexNet()\n",
    "network_state_dict = torch.load('AlexNet.pth', map_location='cpu')\n",
    "model.load_state_dict(network_state_dict)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8445,  0.5438,  0.4589,  0.2408,  0.1983,  0.0510,  0.0862, -0.3756,\n",
      "        -0.0574,  0.6503, -0.0759,  0.2794,  0.0695, -0.6765,  0.1684,  0.1373],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_561354/3924698602.py:22: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  kernels[k] = np.multiply(kernels[k], np.repeat(A[i], channels_out*(img_width**2)))\n",
      "/tmp/ipykernel_561354/1130953881.py:17: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  kernels[k] = np.multiply(kernels[k], np.repeat(A, img_width**2))\n"
     ]
    }
   ],
   "source": [
    "img_width = 32\n",
    "channels = 3\n",
    "kernel_size = 3\n",
    "bin_masks = build_masks(img_width, kernel_size=3, out_channels = 16)\n",
    "\n",
    "initialLayer(img_width, kernel_size, channels_in=channels, channels_out=16, \n",
    "             conv_weight=model.conv1.weight, bn=model.bn1, bin_masks=bin_masks)\n",
    "\n",
    "\n",
    "downsamplingConvbn(img_width, kernel_size, channels_in=16, channels_out=32,\n",
    "                   conv_weight=model.conv2.weight, bn=model.bn2,\n",
    "                   layerNum=2, convNum=1, bin_masks=bin_masks)\n",
    "\n",
    "img_width = int(img_width/2)\n",
    "\n",
    "bin_masks = build_masks(img_width, kernel_size=3, out_channels = 32)\n",
    "\n",
    "downsamplingConvbn(img_width, kernel_size, channels_in=32, channels_out=64,\n",
    "                   conv_weight=model.conv3.weight, bn=model.bn3,\n",
    "                   layerNum=3, convNum=1, bin_masks=bin_masks)\n",
    "\n",
    "img_width = int(img_width/2)\n",
    "\n",
    "bin_masks = build_masks(img_width, kernel_size=3, out_channels = 64)\n",
    "\n",
    "convbn(img_width, kernel_size, channels_in=64, channels_out=64, \n",
    "       conv_weight=model.conv4.weight, bn=model.bn4, \n",
    "       layerNum=4, convNum=1, bin_masks=bin_masks)\n",
    "\n",
    "\n",
    "downsamplingConvbn(img_width, kernel_size, channels_in=64, channels_out=128,\n",
    "                   conv_weight=model.conv5.weight, bn=model.bn5,\n",
    "                   layerNum=5, convNum=1, bin_masks=bin_masks)\n",
    "\n",
    "img_width = int(img_width/2)\n",
    "\n",
    "bin_masks = build_masks(img_width, kernel_size=3, out_channels = 128)\n",
    "\n",
    "convbn(img_width, kernel_size, channels_in=128, channels_out=128, \n",
    "       conv_weight=model.conv6.weight, bn=model.bn6, \n",
    "       layerNum=6, convNum=1, bin_masks=bin_masks)\n",
    "\n",
    "\n",
    "# layer\n",
    "fc(model.fc1.weight, 128*4*4, 100)\n",
    "fc(model.fc2.weight, 100, 10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
