2025-02-27 09:55:20.680229: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-27 09:55:20.682450: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-02-27 09:55:20.710203: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-02-27 09:55:20.710234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-27 09:55:20.711472: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-27 09:55:20.716709: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-02-27 09:55:20.716894: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-27 09:55:21.883012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Misc. initializations
data ready
shape:  (60000, 28, 28, 1)
Validation and test data ready
input shape: (28, 28, 1)
Saving x_test of shape (100, 28, 28, 1) in x_test.h5
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 14, 14, 5)         50        
                                                                 
 batch_normalization (Batch  (None, 14, 14, 5)         20        
 Normalization)                                                  
                                                                 
 square_activation (SquareA  (None, 14, 14, 5)         0         
 ctivation)                                                      
                                                                 
 conv2d_1 (Conv2D)           (None, 7, 7, 10)          460       
                                                                 
 batch_normalization_1 (Bat  (None, 7, 7, 10)          40        
 chNormalization)                                                
                                                                 
 square_activation_1 (Squar  (None, 7, 7, 10)          0         
 eActivation)                                                    
                                                                 
 flatten (Flatten)           (None, 490)               0         
                                                                 
 dense (Dense)               (None, 100)               49100     
                                                                 
 square_activation_2 (Squar  (None, 100)               0         
 eActivation)                                                    
                                                                 
 dense_1 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 50680 (197.97 KB)
Trainable params: 50650 (197.85 KB)
Non-trainable params: 30 (120.00 Byte)
_________________________________________________________________
Epoch 1/50
120/120 - 2s - loss: 7.0034 - accuracy: 0.6596 - val_loss: 2.2248 - val_accuracy: 0.2474 - 2s/epoch - 19ms/step
Epoch 2/50
120/120 - 2s - loss: 0.9244 - accuracy: 0.8693 - val_loss: 1.4913 - val_accuracy: 0.5232 - 2s/epoch - 15ms/step
Epoch 3/50
120/120 - 2s - loss: 0.5019 - accuracy: 0.9090 - val_loss: 0.7096 - val_accuracy: 0.7910 - 2s/epoch - 15ms/step
Epoch 4/50
120/120 - 2s - loss: 0.3319 - accuracy: 0.9310 - val_loss: 0.4003 - val_accuracy: 0.9081 - 2s/epoch - 15ms/step
Epoch 5/50
120/120 - 2s - loss: 0.2466 - accuracy: 0.9435 - val_loss: 0.3015 - val_accuracy: 0.9390 - 2s/epoch - 15ms/step
Epoch 6/50
120/120 - 2s - loss: 0.1891 - accuracy: 0.9540 - val_loss: 0.2757 - val_accuracy: 0.9470 - 2s/epoch - 15ms/step
Epoch 7/50
120/120 - 2s - loss: 0.1569 - accuracy: 0.9594 - val_loss: 0.2784 - val_accuracy: 0.9472 - 2s/epoch - 15ms/step
Epoch 8/50
120/120 - 2s - loss: 0.1291 - accuracy: 0.9659 - val_loss: 0.2498 - val_accuracy: 0.9538 - 2s/epoch - 15ms/step
Epoch 9/50
120/120 - 2s - loss: 0.1069 - accuracy: 0.9706 - val_loss: 0.2469 - val_accuracy: 0.9559 - 2s/epoch - 15ms/step
Epoch 10/50
120/120 - 2s - loss: 0.0916 - accuracy: 0.9750 - val_loss: 0.2334 - val_accuracy: 0.9559 - 2s/epoch - 15ms/step
Epoch 11/50
120/120 - 2s - loss: 0.0814 - accuracy: 0.9771 - val_loss: 0.2171 - val_accuracy: 0.9583 - 2s/epoch - 15ms/step
Epoch 12/50
120/120 - 2s - loss: 0.0735 - accuracy: 0.9793 - val_loss: 0.2236 - val_accuracy: 0.9584 - 2s/epoch - 15ms/step
Epoch 13/50
120/120 - 2s - loss: 0.0627 - accuracy: 0.9817 - val_loss: 0.2055 - val_accuracy: 0.9627 - 2s/epoch - 15ms/step
Epoch 14/50
120/120 - 2s - loss: 0.0531 - accuracy: 0.9849 - val_loss: 0.2030 - val_accuracy: 0.9634 - 2s/epoch - 15ms/step
Epoch 15/50
120/120 - 2s - loss: 0.0466 - accuracy: 0.9864 - val_loss: 0.2052 - val_accuracy: 0.9638 - 2s/epoch - 15ms/step
Epoch 16/50
120/120 - 2s - loss: 0.0428 - accuracy: 0.9871 - val_loss: 0.2064 - val_accuracy: 0.9646 - 2s/epoch - 15ms/step
Epoch 17/50
120/120 - 2s - loss: 0.0398 - accuracy: 0.9884 - val_loss: 0.2188 - val_accuracy: 0.9640 - 2s/epoch - 15ms/step
Epoch 18/50
120/120 - 2s - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.2057 - val_accuracy: 0.9658 - 2s/epoch - 15ms/step
Epoch 19/50
120/120 - 2s - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.2015 - val_accuracy: 0.9663 - 2s/epoch - 15ms/step
Epoch 20/50
120/120 - 2s - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.2033 - val_accuracy: 0.9642 - 2s/epoch - 15ms/step
Epoch 21/50
120/120 - 2s - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.2025 - val_accuracy: 0.9672 - 2s/epoch - 15ms/step
Epoch 22/50
120/120 - 2s - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.2107 - val_accuracy: 0.9691 - 2s/epoch - 15ms/step
Epoch 23/50
120/120 - 2s - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.2088 - val_accuracy: 0.9681 - 2s/epoch - 15ms/step
Epoch 24/50
120/120 - 2s - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.2053 - val_accuracy: 0.9683 - 2s/epoch - 15ms/step
Epoch 25/50
120/120 - 2s - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.1990 - val_accuracy: 0.9712 - 2s/epoch - 15ms/step
Epoch 26/50
120/120 - 2s - loss: 0.0309 - accuracy: 0.9908 - val_loss: 0.2713 - val_accuracy: 0.9682 - 2s/epoch - 15ms/step
Epoch 27/50
120/120 - 2s - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.2404 - val_accuracy: 0.9714 - 2s/epoch - 15ms/step
Epoch 28/50
120/120 - 2s - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.2174 - val_accuracy: 0.9712 - 2s/epoch - 15ms/step
Epoch 29/50
120/120 - 2s - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.2363 - val_accuracy: 0.9712 - 2s/epoch - 15ms/step
Epoch 30/50
120/120 - 2s - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.2484 - val_accuracy: 0.9699 - 2s/epoch - 15ms/step
Epoch 31/50
120/120 - 2s - loss: 0.0286 - accuracy: 0.9928 - val_loss: 0.2544 - val_accuracy: 0.9700 - 2s/epoch - 15ms/step
Epoch 32/50
120/120 - 2s - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.2243 - val_accuracy: 0.9721 - 2s/epoch - 15ms/step
Epoch 33/50
120/120 - 2s - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.2944 - val_accuracy: 0.9689 - 2s/epoch - 15ms/step
Epoch 34/50
120/120 - 2s - loss: 0.0224 - accuracy: 0.9940 - val_loss: 0.2309 - val_accuracy: 0.9739 - 2s/epoch - 15ms/step
Epoch 35/50
120/120 - 2s - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.2246 - val_accuracy: 0.9747 - 2s/epoch - 13ms/step
Epoch 36/50
120/120 - 2s - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.2299 - val_accuracy: 0.9734 - 2s/epoch - 15ms/step
Epoch 37/50
120/120 - 2s - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.2630 - val_accuracy: 0.9730 - 2s/epoch - 15ms/step
Epoch 38/50
120/120 - 2s - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.2664 - val_accuracy: 0.9720 - 2s/epoch - 15ms/step
Epoch 39/50
120/120 - 2s - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.2040 - val_accuracy: 0.9751 - 2s/epoch - 15ms/step
Epoch 40/50
120/120 - 2s - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.2479 - val_accuracy: 0.9709 - 2s/epoch - 15ms/step
Epoch 41/50
120/120 - 2s - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.2500 - val_accuracy: 0.9742 - 2s/epoch - 15ms/step
Epoch 42/50
120/120 - 2s - loss: 0.0322 - accuracy: 0.9929 - val_loss: 0.2441 - val_accuracy: 0.9754 - 2s/epoch - 15ms/step
Epoch 43/50
120/120 - 2s - loss: 0.0290 - accuracy: 0.9933 - val_loss: 0.2874 - val_accuracy: 0.9738 - 2s/epoch - 15ms/step
Epoch 44/50
120/120 - 2s - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.2076 - val_accuracy: 0.9763 - 2s/epoch - 14ms/step
Epoch 45/50
120/120 - 2s - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.2607 - val_accuracy: 0.9743 - 2s/epoch - 15ms/step
Epoch 46/50
120/120 - 2s - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.2324 - val_accuracy: 0.9784 - 2s/epoch - 14ms/step
Epoch 47/50
120/120 - 2s - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.2450 - val_accuracy: 0.9771 - 2s/epoch - 15ms/step
Epoch 48/50
120/120 - 2s - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.2243 - val_accuracy: 0.9789 - 2s/epoch - 15ms/step
Epoch 49/50
120/120 - 2s - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.2004 - val_accuracy: 0.9797 - 2s/epoch - 15ms/step
Epoch 50/50
120/120 - 2s - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.2174 - val_accuracy: 0.9788 - 2s/epoch - 15ms/step
Test loss: 0.063
Test accuracy: 98.000%
Test loss: 2.941
Test accuracy: 98.000%
Saved model to disk
